{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f64bde6f-f4e0-44f1-992e-bf35a94280e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 13:22:32.757951: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-11 13:22:32.758041: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-11 13:22:32.760175: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-11 13:22:32.770318: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-11 13:22:36.396641: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version = 2.15.1\n"
     ]
    }
   ],
   "source": [
    "import os, gc\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2\"\n",
    "import tensorflow as tf\n",
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print('TensorFlow version =',tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eb29708-4ea1-4530-b12e-9f9c224b0fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 0 GPU\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "from UNet_HCRF_src.utility import UNet_layer\n",
    "from UNet_HCRF_src.UNet_HCRF_model import unet_global\n",
    "\n",
    "\n",
    "# USE MULTIPLE GPUS\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if len(gpus)<=1: \n",
    "    strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n",
    "    print(f'Using {len(gpus)} GPU')\n",
    "else: \n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    print(f'Using {len(gpus)} GPUs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df94a36e-be92-47aa-a765-d693020a7bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train non-overlapp eeg_id shape: (17089, 16)\n",
      "Train shape: (17089, 16)\n",
      "Targets ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n",
      "Unique EEG id: (17089,)\n",
      "Spectrogram id: (11138,)\n",
      "Unique EEG_Spectrogram id: 17089\n",
      "Non-unique spectrogram id upper bound:1\n",
      "Non-unique eeg id upper bound:107\n",
      "Over 10 experts rated records:(10143, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>spectrogram_id</th>\n",
       "      <th>spec_min</th>\n",
       "      <th>spec_max</th>\n",
       "      <th>eeg_min</th>\n",
       "      <th>eeg_max</th>\n",
       "      <th>eeg_mean</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>expert_numner</th>\n",
       "      <th>seizure_vote</th>\n",
       "      <th>lpd_vote</th>\n",
       "      <th>gpd_vote</th>\n",
       "      <th>lrda_vote</th>\n",
       "      <th>grda_vote</th>\n",
       "      <th>other_vote</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>568657</td>\n",
       "      <td>789577333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>20654</td>\n",
       "      <td>48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>582999</td>\n",
       "      <td>1552638400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>17.454545</td>\n",
       "      <td>20230</td>\n",
       "      <td>154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>LPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>642382</td>\n",
       "      <td>14960202</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5955</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>751790</td>\n",
       "      <td>618728447</td>\n",
       "      <td>908.0</td>\n",
       "      <td>908.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38549</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>GPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>778705</td>\n",
       "      <td>52296320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40955</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eeg_id  spectrogram_id  spec_min  spec_max  eeg_min  eeg_max   eeg_mean  \\\n",
       "0  568657       789577333       0.0      16.0      0.0     16.0   8.500000   \n",
       "1  582999      1552638400       0.0      38.0      0.0     38.0  17.454545   \n",
       "2  642382        14960202    1008.0    1032.0      0.0     24.0  12.000000   \n",
       "3  751790       618728447     908.0     908.0      0.0      0.0   0.000000   \n",
       "4  778705        52296320       0.0       0.0      0.0      0.0   0.000000   \n",
       "\n",
       "   patient_id  expert_numner  seizure_vote  lpd_vote  gpd_vote  lrda_vote  \\\n",
       "0       20654             48           0.0  0.000000      0.25   0.000000   \n",
       "1       20230            154           0.0  0.857143      0.00   0.071429   \n",
       "2        5955              2           0.0  0.000000      0.00   0.000000   \n",
       "3       38549              1           0.0  0.000000      1.00   0.000000   \n",
       "4       40955              2           0.0  0.000000      0.00   0.000000   \n",
       "\n",
       "   grda_vote  other_vote target  \n",
       "0   0.166667    0.583333  Other  \n",
       "1   0.000000    0.071429    LPD  \n",
       "2   0.000000    1.000000  Other  \n",
       "3   0.000000    0.000000    GPD  \n",
       "4   0.000000    1.000000  Other  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./dataset/train.csv')\n",
    "TARGETS = df.columns[-6:]\n",
    "\n",
    "train = df.groupby('eeg_id')[['spectrogram_id','spectrogram_label_offset_seconds']].agg(\n",
    "    {'spectrogram_id':'first','spectrogram_label_offset_seconds':'min'})\n",
    "train.columns = ['spectrogram_id','spec_min']\n",
    "\n",
    "tmp = df.groupby('eeg_id')[['spectrogram_id','spectrogram_label_offset_seconds']].agg(\n",
    "    {'spectrogram_label_offset_seconds':'max'})\n",
    "train['spec_max'] = tmp\n",
    "\n",
    "tmp = df.groupby('eeg_id')[['spectrogram_id', 'eeg_label_offset_seconds']].agg(\n",
    "    {'eeg_label_offset_seconds':'min' }\n",
    ")\n",
    "train['eeg_min'] = tmp\n",
    "\n",
    "tmp = df.groupby('eeg_id')[['spectrogram_id', 'eeg_label_offset_seconds']].agg(\n",
    "    {'eeg_label_offset_seconds':'max' }\n",
    ")\n",
    "train['eeg_max'] = tmp\n",
    "\n",
    "tmp = df.groupby('eeg_id')[['spectrogram_id', 'eeg_label_offset_seconds']].agg(\n",
    "    {'eeg_label_offset_seconds':'mean' }\n",
    ")\n",
    "train['eeg_mean'] = tmp\n",
    "\n",
    "tmp = df.groupby('eeg_id')[['patient_id']].agg('first')\n",
    "train['patient_id'] = tmp\n",
    "\n",
    "tmp = df.groupby('eeg_id')[TARGETS].agg('sum')\n",
    "train['expert_numner'] = tmp.sum(axis=1)\n",
    "for t in TARGETS:\n",
    "    train[t] = tmp[t].values\n",
    "\n",
    "y_data = train[TARGETS].values\n",
    "y_data = y_data / y_data.sum(axis=1,keepdims=True)\n",
    "train[TARGETS] = y_data\n",
    "\n",
    "tmp = df.groupby('eeg_id')[['expert_consensus']].agg('first')\n",
    "train['target'] = tmp\n",
    "\n",
    "train = train.reset_index()\n",
    "print('Train non-overlapp eeg_id shape:', train.shape )\n",
    "train.head()\n",
    "####################\n",
    "\n",
    "TARGETS = train.columns[-7:-1]\n",
    "print('Train shape:', train.shape)\n",
    "print('Targets', list(TARGETS))\n",
    "print('Unique EEG id:', train.eeg_id.unique().shape)\n",
    "print('Spectrogram id:', train.spectrogram_id.unique().shape)\n",
    "print('Unique EEG_Spectrogram id:', train.groupby(['eeg_id', 'spectrogram_id']).agg('first').shape[0])\n",
    "# tmp_index = train.eeg_label_offset_seconds > train.spectrogram_label_offset_seconds\n",
    "# print('Eeg offset time longer: ', train[tmp_index].shape[0])\n",
    "# tmp_index = train.eeg_label_offset_seconds < train.spectrogram_label_offset_seconds\n",
    "# print('Spectrogram offset time longer: ', train[tmp_index].shape[0])\n",
    "tmp = train.groupby('eeg_id').apply(lambda x: len(np.unique(x['spectrogram_id'].values)))\n",
    "print(f'Non-unique spectrogram id upper bound:{tmp.max()}')\n",
    "tmp = train.groupby('spectrogram_id').apply(lambda x: len(np.unique(x['eeg_id'].values)))\n",
    "print(f'Non-unique eeg id upper bound:{tmp.max()}')\n",
    "# pd.DataFrame.groupby()\n",
    "print(f'Over 10 experts rated records:{train[train.expert_numner > 10].shape}')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c637389-0842-47b4-8144-f881fb0c4042",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import importlib\n",
    "import utility\n",
    "importlib.reload(utility)\n",
    "import pandas as pd\n",
    "directory_path = 'dataset/non_overlap_eeg_spec/'\n",
    "PATH = 'dataset/train_eegs/'\n",
    "DISPLAY = 4\n",
    "EEG_info = train[['eeg_id', 'eeg_min', 'eeg_max']].values\n",
    "all_eegs = {}\n",
    "READ_EGG = False\n",
    "SAVE_EGG_SPEC = False\n",
    "if READ_EGG:\n",
    "    for i,eeg_info in enumerate(EEG_info):\n",
    "        # eeg_id, middle = int(eeg_info[0]), (eeg_info[1] + eeg_info[2]) // 2\n",
    "        eeg_id, middle = int(eeg_info[0]), eeg_info[1]\n",
    "        if (i%100==0)&(i!=0): print(i,', ',end='')\n",
    "        # CREATE SPECTROGRAM FROM EEG PARQUET\n",
    "        img = spectrogram_from_eeg(f'{PATH}{eeg_id}.parquet', i<DISPLAY, off_set= middle)\n",
    "        \n",
    "        # SAVE TO DISK\n",
    "        if i==DISPLAY:\n",
    "            print(f'Creating and writing {EEG_info.shape[0]} spectrograms to disk... ',end='')\n",
    "        np.save(f'{directory_path}{eeg_id}',img)\n",
    "        all_eegs[eeg_id] = img\n",
    "    if SAVE_EGG_SPEC:\n",
    "    # SAVE EEG SPECTROGRAM DICTIONARY\n",
    "        np.save('mean_non_overlap_eeg_specs_non_denoise',all_eegs)\n",
    "else:\n",
    "    all_eegs = np.load('dataset/non_overlap_eeg_specs_non_denoise.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6c0354-d828-4878-8df3-5d716804cfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "READ_SPEC_FILES = False\n",
    "\n",
    "# READ ALL SPECTROGRAMS\n",
    "PATH = './dataset/train_spectrograms/'\n",
    "files = os.listdir(PATH)\n",
    "print(f'There are {len(files)} spectrogram parquets')\n",
    "\n",
    "if READ_SPEC_FILES:    \n",
    "    spectrograms = {}\n",
    "    for i,f in enumerate(files):\n",
    "        if i%100==0: print(i,', ',end='')\n",
    "        tmp = pd.read_parquet(f'{PATH}{f}')\n",
    "        name = int(f.split('.')[0])\n",
    "        spectrograms[name] = tmp.iloc[:,1:].values\n",
    "else:\n",
    "    spectrograms = np.load('./dataset/spec.npy',allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6988cbc2-f3e8-42f2-bc7f-8a5f946d2eff",
   "metadata": {},
   "source": [
    "### Dataloader for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5d2268-20ce-42c0-97b2-efecd861fdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as albu\n",
    "TARS = {'Seizure':0, 'LPD':1, 'GPD':2, 'LRDA':3, 'GRDA':4, 'Other':5}\n",
    "TARS2 = {x:y for y,x in TARS.items()}\n",
    "\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, data, batch_size=32, shuffle=False, augment=False, mode='train',\n",
    "                 specs = spectrograms, eeg_specs = all_eegs):\n",
    "\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.augment = augment\n",
    "        self.mode = mode\n",
    "        self.specs = specs\n",
    "        self.eeg_specs = eeg_specs\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        ct = int( np.ceil( len(self.data) / self.batch_size ) )\n",
    "        return ct\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        X, y = self.__data_generation(indexes)\n",
    "        if self.augment: X = self.__augment_batch(X)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange( len(self.data) )\n",
    "        if self.shuffle: np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, indexes):\n",
    "        'Generates data containing batch_size samples'\n",
    "\n",
    "        X = np.zeros((len(indexes),128,256,8),dtype='float32')\n",
    "        y = np.zeros((len(indexes),6),dtype='float32')\n",
    "        img = np.ones((128,256),dtype='float32')\n",
    "\n",
    "        for j,i in enumerate(indexes):\n",
    "            row = self.data.iloc[i]\n",
    "            if self.mode=='test':\n",
    "                r = 0\n",
    "            else:\n",
    "                r = int( (row['spec_min'] + row['spec_max'])//4 )\n",
    "\n",
    "            for k in range(4):\n",
    "                # EXTRACT 300 ROWS OF SPECTROGRAM\n",
    "                img = self.specs[row.spectrogram_id][r:r+300,k*100:(k+1)*100].T\n",
    "\n",
    "                # LOG TRANSFORM SPECTROGRAM\n",
    "                img = np.clip(img,np.exp(-4),np.exp(8))\n",
    "                img = np.log(img)\n",
    "\n",
    "                # STANDARDIZE PER IMAGE\n",
    "                ep = 1e-6\n",
    "                m = np.nanmean(img.flatten())\n",
    "                s = np.nanstd(img.flatten())\n",
    "                img = (img-m)/(s+ep)\n",
    "                img = np.nan_to_num(img, nan=0.0)\n",
    "\n",
    "                # CROP TO 256 TIME STEPS\n",
    "                X[j,14:-14,:,k] = img[:,22:-22] / 2.0\n",
    "\n",
    "            # EEG SPECTROGRAMS\n",
    "            img = self.eeg_specs[row.eeg_id]\n",
    "            X[j,:,:,4:] = img\n",
    "\n",
    "            if self.mode!='test':\n",
    "                y[j,] = row[TARGETS]\n",
    "\n",
    "        return X,y\n",
    "\n",
    "    def __random_transform(self, img):\n",
    "        composition = albu.Compose([\n",
    "            albu.HorizontalFlip(p=0.5),\n",
    "            #albu.CoarseDropout(max_holes=8,max_height=32,max_width=32,fill_value=0,p=0.5),\n",
    "        ])\n",
    "        return composition(image=img)['image']\n",
    "\n",
    "    def __augment_batch(self, img_batch):\n",
    "        for i in range(img_batch.shape[0]):\n",
    "            img_batch[i, ] = self.__random_transform(img_batch[i, ])\n",
    "        return img_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ed6e8c-a472-4814-b4cd-81fddd4fde64",
   "metadata": {},
   "source": [
    "### Build global unet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5849d39-92d1-4aa3-abba-3ab4b46b4a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    Layer,\n",
    "    Conv2D,\n",
    "    UpSampling2D,\n",
    "    AveragePooling2D,\n",
    "    LeakyReLU,\n",
    "    Input,\n",
    "    concatenate,\n",
    "    BatchNormalization,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Activation,\n",
    "    Add,\n",
    "    GlobalAveragePooling2D,\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from crfasrnn_keras.src.crfrnn_layer import CrfRnnLayer\n",
    "from crfasrnn_keras.src.hidden_crfnn_layer import HiddenCrfRnnLayer\n",
    "\n",
    "class UNet_layer(Layer):\n",
    "    def __init__(self, input_shape, num_classes=6, num_features=32, blocks=[1, 2, 4, 8, 16], trainable=False, **kwargs):\n",
    "        super(UNet_layer, self).__init__(**kwargs)\n",
    "\n",
    "        # Save parameters\n",
    "        self.input_shape_ = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.num_features = num_features\n",
    "        self.blocks = blocks\n",
    "        self.trainable = trainable\n",
    "\n",
    "        # Define down-sampling layers\n",
    "        self.down_stack = []\n",
    "        for i, block in enumerate(self.blocks):\n",
    "            self.down_stack.append(\n",
    "                [\n",
    "                    Conv2D(self.num_features * block, 3, strides=1, padding=\"same\"),\n",
    "                    BatchNormalization(),\n",
    "                    LeakyReLU(alpha=0.1),\n",
    "                    Conv2D(self.num_features * block, 3, strides=1, padding=\"same\"),\n",
    "                    BatchNormalization(),\n",
    "                    LeakyReLU(alpha=0.1, name=f\"down_block_relu_{i}\"),\n",
    "                    AveragePooling2D(pool_size=(2, 2), strides=2, padding=\"same\") if i < len(self.blocks) - 1 else None,\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        # Define up-sampling layers\n",
    "        self.up_stack = []\n",
    "        for i, block in enumerate(self.blocks[:-1][::-1]):\n",
    "            self.up_stack.append(\n",
    "                [\n",
    "                    UpSampling2D(size=(2, 2)),\n",
    "                    Conv2D(self.num_features * block, 3, strides=1, padding=\"same\"),\n",
    "                    BatchNormalization(),\n",
    "                    LeakyReLU(alpha=0.1),\n",
    "                    Conv2D(self.num_features * block, 3, strides=1, padding=\"same\"),\n",
    "                    BatchNormalization(),\n",
    "                    LeakyReLU(alpha=0.1),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        \"\"\"\n",
    "        Forward pass through the U-Net.\n",
    "        \"\"\"\n",
    "        # Down-sampling path\n",
    "        x = inputs\n",
    "        skip_connections = []\n",
    "        for i, block_layers in enumerate(self.down_stack):\n",
    "            for layer in block_layers[:-1]:  # Skip the pooling layer in the last block\n",
    "                x = layer(x, training=training)\n",
    "            if block_layers[-1] is not None:  # Add skip connection and apply pooling if not the last block\n",
    "                skip_connections.append(x)\n",
    "                x = block_layers[-1](x)\n",
    "\n",
    "        # Up-sampling path\n",
    "        for i, (block_layers, skip) in enumerate(zip(self.up_stack, skip_connections[::-1])):\n",
    "            x = block_layers[0](x)  # Up-sample\n",
    "            x = concatenate([x, skip], axis=-1)  # Concatenate with skip connection\n",
    "            for layer in block_layers[1:]:  # Apply convolutional layers\n",
    "                x = layer(x, training=training)\n",
    "\n",
    "        return x\n",
    "\n",
    "def unet_global(image_size=(512, 512), num_classes=6, **kwargs):\n",
    "    \"\"\"\n",
    "    Define the full U-Net model.\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=image_size + (3,))\n",
    "    unet_layer_instance = UNet_layer(input_shape=image_size + (3,), **kwargs)\n",
    "    extract_feature = unet_layer_instance(inputs)\n",
    "\n",
    "    # Further processing\n",
    "    x = Conv2D(filters=64, kernel_size=3, strides=1, padding=\"same\")(extract_feature)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = AveragePooling2D(2, strides=2, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(filters=128, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = AveragePooling2D(2, strides=2, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(units=265, activation=\"relu\")(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    global_map = Dense(units=num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=global_map)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "    loss = tf.keras.losses.KLDivergence()\n",
    "\n",
    "    model.compile(loss=loss, optimizer=opt)\n",
    "    return model\n",
    "\n",
    "\n",
    "def unet_hidden_crf(image_size=(512, 512), num_classes=6, pretrained_weights_path=None, **kwargs):\n",
    "    inputs = Input(shape=image_size + (3,))\n",
    "\n",
    "    unet_layer_instance = UNet_layer(input_shape=image_size + (3,), **kwargs)\n",
    "    extract_feature = unet_layer_instance(inputs)\n",
    "\n",
    "    feature_map = Conv2D(filters=num_classes, kernel_size=1, strides=1, padding=\"same\")(extract_feature)\n",
    "    feature_map = Activation('softmax', name='before_crf')(feature_map)\n",
    "\n",
    "    x = Conv2D(filters=64, kernel_size=3, strides=1, padding=\"same\")(extract_feature)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = AveragePooling2D(2, strides=2, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(filters=128, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = AveragePooling2D(2, strides=2, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(units=265, activation=\"relu\")(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    global_map = Dense(units=num_classes, activation=\"softmax\", name=\"global_map\")(x)\n",
    "\n",
    "    \n",
    "    crf = HiddenCrfRnnLayer(\n",
    "        image_dims=image_size + (3,),\n",
    "        num_classes=num_classes,\n",
    "        theta_alpha=4.46,\n",
    "        theta_beta=4.5,\n",
    "        theta_gamma=0.11,\n",
    "        num_iterations=1,\n",
    "        trainable=True,\n",
    "        name='hiddencrfrnn_trainable'\n",
    "    )([feature_map, feature_map])\n",
    "\n",
    "    # post_crf = Conv2D(filters=num_classes, kernel_size=1, strides=1, padding=\"same\")(crf)\n",
    "\n",
    "    log_global_map = tf.math.log(global_map + 1e-10)\n",
    "    combined = Add(name=\"final_combination\")([crf, log_global_map])\n",
    "    outputs = Activation('softmax', name='final_result')(combined)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    #Load pretrained weights selectively\n",
    "    # if pretrained_weights_path:\n",
    "    #     try:\n",
    "    #         print(f\"Loading pretrained weights from {pretrained_weights_path}...\")\n",
    "    #         model.load_weights(pretrained_weights_path)\n",
    "    #     except Exception as e:\n",
    "    #         print(f\"Error loading pretrained weights: {e}\")\n",
    "\n",
    "    return model\n",
    "# def unet_hidden_crf(image_size=(512, 512), num_classes=6, pretrained_weights_path=None, **kwargs):\n",
    "#     \"\"\"\n",
    "#     Define the full U-Net model and optionally initialize parameters from a pretrained model without relying on layer names.\n",
    "#     \"\"\"\n",
    "#     inputs = Input(shape=image_size + (3,))\n",
    "    \n",
    "#     # Initialize U-Net layers\n",
    "#     unet_layer_instance = UNet_layer(input_shape=image_size + (3,), **kwargs)\n",
    "#     extract_feature = unet_layer_instance(inputs)\n",
    "\n",
    "#     # Further processing layers\n",
    "#     x = Conv2D(filters=64, kernel_size=3, strides=1, padding=\"same\")(extract_feature)\n",
    "#     x = LeakyReLU(alpha=0.1)(x)\n",
    "#     x = AveragePooling2D(2, strides=2, padding=\"same\")(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "\n",
    "#     x = Conv2D(filters=128, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "#     x = LeakyReLU(alpha=0.1)(x)\n",
    "#     x = AveragePooling2D(2, strides=2, padding=\"same\")(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "\n",
    "#     x = GlobalAveragePooling2D()(x)\n",
    "#     x = Dense(units=265, activation=\"relu\")(x)\n",
    "#     x = Dropout(0.3)(x)\n",
    "#     global_map = Dense(units=num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "#     # Add CRF layers\n",
    "#     feature_map = Conv2D(filters=num_classes, kernel_size=1, strides=1, padding=\"same\")(extract_feature)\n",
    "#     feature_map = Activation('softmax', name='before_crf')(feature_map)\n",
    "    \n",
    "#     crf = HiddenCrfRnnLayer(\n",
    "#         image_dims=image_size + (3, ),\n",
    "#         num_classes=num_classes,\n",
    "#         theta_alpha=4.46,\n",
    "#         theta_beta=4.5,\n",
    "#         theta_gamma=0.11,\n",
    "#         num_iterations=1,\n",
    "#         trainable=True,\n",
    "#         name='hiddencrfrnn_trainable'\n",
    "#     )([feature_map, feature_map, global_map])\n",
    "    \n",
    "#     # crf = CrfRnnLayer(\n",
    "#     #     image_dims=image_size + (3, ),\n",
    "#     #     num_classes=num_classes,\n",
    "#     #     theta_alpha=4.46,\n",
    "#     #     theta_beta=4.5,\n",
    "#     #     theta_gamma=0.11,\n",
    "#     #     num_iterations=1,\n",
    "#     #     trainable=True,\n",
    "#     #     name='hiddencrfrnn_trainable'\n",
    "#     # )([feature_map, feature_map, global_map])\n",
    "\n",
    "#     post_crf = Conv2D(filters=num_classes, kernel_size=1, strides=1, padding=\"same\")(crf)\n",
    "#     outputs = Activation('softmax', name='final_result')(post_crf)\n",
    "    \n",
    "#     model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "#     # Load pretrained weights selectively\n",
    "#     if pretrained_weights_path:\n",
    "#         try:\n",
    "#             print(f\"Loading pretrained weights from {pretrained_weights_path}...\")\n",
    "#             pretrained_model = Model(inputs=inputs, outputs=global_map)\n",
    "#             pretrained_model.load_weights(pretrained_weights_path)  # Load weights for layers up to `global_map`\n",
    "            \n",
    "#             # Extract pretrained weights\n",
    "#             pretrained_weights = pretrained_model.get_weights()\n",
    "#             model_weights = model.get_weights()\n",
    "            \n",
    "#             # Update weights for matching layers\n",
    "#             for i in range(len(pretrained_weights)):\n",
    "#                 if pretrained_weights[i].shape == model_weights[i].shape:\n",
    "#                     model_weights[i] = pretrained_weights[i]\n",
    "#                 else:\n",
    "#                     print(f\"Skipping layer {i}: shape mismatch {pretrained_weights[i].shape} vs {model_weights[i].shape}\")\n",
    "            \n",
    "#             # Set updated weights back to the full model\n",
    "#             model.set_weights(model_weights)\n",
    "#             print(\"Pretrained weights successfully loaded for layers up to `global_map`.\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error loading pretrained weights: {e}\")\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba4445b-4542-4493-bdc2-5cb3d6ebcd5c",
   "metadata": {},
   "source": [
    "### Train Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd138f7-5e1b-4e73-9c82-c0cd671379db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "LR_START = 1e-6\n",
    "LR_MAX = 1e-3\n",
    "LR_MIN = 1e-7\n",
    "LR_RAMPUP_EPOCHS = 0\n",
    "LR_SUSTAIN_EPOCHS = 0\n",
    "EPOCHS = 50\n",
    "\n",
    "def lrfn(epoch):\n",
    "    if epoch < LR_RAMPUP_EPOCHS:\n",
    "        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
    "    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
    "        lr = LR_MAX\n",
    "    else:\n",
    "        decay_total_epochs = EPOCHS - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS - 1\n",
    "        decay_epoch_index = epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS\n",
    "        phase = math.pi * decay_epoch_index / decay_total_epochs\n",
    "        cosine_decay = 0.5 * (1 + math.cos(phase))\n",
    "        lr = (LR_MAX - LR_MIN) * cosine_decay + LR_MIN\n",
    "    return lr\n",
    "\n",
    "rng = [i for i in range(EPOCHS)]\n",
    "lr_y = [lrfn(x) for x in rng]\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(rng, lr_y, '-o')\n",
    "plt.xlabel('epoch',size=14); plt.ylabel('learning rate',size=14)\n",
    "plt.title('Cosine Training Schedule',size=16); plt.show()\n",
    "\n",
    "LR2 = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21481465-a462-4922-8cfa-33cafb5ca8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_KAGGLE_SPECTROGRAMS = True\n",
    "USE_EEG_SPECTROGRAMS = True\n",
    "def build_model(base_model):\n",
    "\n",
    "    inp = tf.keras.Input(shape=(128,256,8))\n",
    "    # base_model = None \n",
    "    \n",
    "    # RESHAPE INPUT 128x256x8 => 512x512x3 MONOTONE IMAGE\n",
    "    # KAGGLE SPECTROGRAMS\n",
    "    x1 = [inp[:,:,:,i:i+1] for i in range(4)]\n",
    "    x1 = tf.keras.layers.Concatenate(axis=1)(x1)\n",
    "    # EEG SPECTROGRAMS\n",
    "    x2 = [inp[:,:,:,i+4:i+5] for i in range(4)]\n",
    "    x2 = tf.keras.layers.Concatenate(axis=1)(x2)\n",
    "    # MAKE 512X512X3\n",
    "    if USE_KAGGLE_SPECTROGRAMS & USE_EEG_SPECTROGRAMS:\n",
    "        x = tf.keras.layers.Concatenate(axis=2)([x1,x2])\n",
    "    elif USE_EEG_SPECTROGRAMS: x = x2\n",
    "    else: x = x1\n",
    "    x = tf.keras.layers.Concatenate(axis=3)([x,x,x])\n",
    "    # OUTPUT\n",
    "    x = base_model(x)\n",
    "    # x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # x = tf.expand_dims(tf.reduce_sum(x, axis=0), axis=0)\n",
    "    # x = tf.keras.layers.Dense(6,activation='softmax', dtype='float32')(x)\n",
    "    \n",
    "    # COMPILE MODEL\n",
    "    model = tf.keras.Model(inputs=inp, outputs=x)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
    "    loss = tf.keras.losses.KLDivergence()\n",
    "\n",
    "    model.compile(loss=loss, optimizer = opt, metrics=[tf.keras.losses.KLDivergence()])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48375207-fbe8-4d38-92ac-08a2f03b5969",
   "metadata": {},
   "source": [
    "### Pretrain Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a24c862-2762-427d-ac46-7a46f1ec69d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "import tensorflow.keras.backend as K, gc\n",
    "\n",
    "LOAD_MODELS_FROM = './Models/'\n",
    "VER = 1\n",
    "NUM_EXPERTS_THRESHOLD = 10\n",
    "# VER = 1\n",
    "all_oof = []\n",
    "all_true = []\n",
    "train_data = train[train.expert_numner > NUM_EXPERTS_THRESHOLD]\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "for i, (train_index, valid_index) in enumerate(gkf.split(train_data, train_data.target, train_data.patient_id)):  \n",
    "    \n",
    "    print('#'*25)\n",
    "    print(f'### Fold {i+1}')\n",
    "    \n",
    "    train_gen = DataGenerator(train_data.iloc[train_index], shuffle=True, batch_size=32, augment=False)\n",
    "    valid_gen = DataGenerator(train_data.iloc[valid_index], shuffle=False, batch_size=64, mode='valid')\n",
    "    \n",
    "    print(f'### train size {len(train_index)}, valid size {len(valid_index)}')\n",
    "    print('#'*25)\n",
    "    \n",
    "    K.clear_session()       \n",
    "    with strategy.scope():\n",
    "        image_size = (512, 512)\n",
    "        num_classes = 6\n",
    "        model = unet_global(image_size = image_size, num_classes=num_classes, num_features=32, trainable=True)\n",
    "        model = build_model(model)\n",
    "    if LOAD_MODELS_FROM is None:\n",
    "        model.fit(train_gen, verbose=1,\n",
    "              validation_data = valid_gen,\n",
    "              epochs=EPOCHS, callbacks = [LR2],)\n",
    "        model.save_weights(f'Global_UNet_v{VER}_f{i}.h5')\n",
    "    else:\n",
    "        model.load_weights(f'{LOAD_MODELS_FROM}Global_UNet_v{VER}_f{i}.h5')\n",
    "        model.evaluate(valid_gen)\n",
    "        # model.save(f'{LOAD_MODELS_FROM}Global_UNet_v{VER}_f{i}_full.h5')\n",
    "    oof = model.predict(valid_gen, verbose=1)\n",
    "    all_oof.append(oof)\n",
    "    all_true.append(train_data.iloc[valid_index][TARGETS].values)\n",
    "    del model, oof\n",
    "    gc.collect()\n",
    "    \n",
    "all_oof = np.concatenate(all_oof)\n",
    "all_true = np.concatenate(all_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecf55de-8569-4147-92b2-c5adb391212c",
   "metadata": {},
   "source": [
    "### Fine tune Hidden CRF layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fceb880-b1f5-49e4-8c53-c84d69887940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "LR_START = 1e-6\n",
    "LR_MAX = 1e-3\n",
    "LR_MIN = 1e-7\n",
    "LR_RAMPUP_EPOCHS = 0\n",
    "LR_SUSTAIN_EPOCHS = 0\n",
    "EPOCHS = 5\n",
    "\n",
    "def lrfn(epoch):\n",
    "    if epoch < LR_RAMPUP_EPOCHS:\n",
    "        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
    "    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
    "        lr = LR_MAX\n",
    "    else:\n",
    "        decay_total_epochs = EPOCHS - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS - 1\n",
    "        decay_epoch_index = epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS\n",
    "        phase = math.pi * decay_epoch_index / decay_total_epochs\n",
    "        cosine_decay = 0.5 * (1 + math.cos(phase))\n",
    "        lr = (LR_MAX - LR_MIN) * cosine_decay + LR_MIN\n",
    "    return lr\n",
    "\n",
    "rng = [i for i in range(EPOCHS)]\n",
    "lr_y = [lrfn(x) for x in rng]\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(rng, lr_y, '-o')\n",
    "plt.xlabel('epoch',size=14); plt.ylabel('learning rate',size=14)\n",
    "plt.title('Cosine Training Schedule',size=16); plt.show()\n",
    "\n",
    "LR2 = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34d82c5-cef2-4e37-86c7-0e2b12a4039a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "import tensorflow.keras.backend as K, gc\n",
    "\n",
    "LOAD_MODELS_FROM = None\n",
    "BATCH_SIZE = 1\n",
    "VER = 2\n",
    "NUM_EXPERTS_THRESHOLD = 10\n",
    "all_oof = []\n",
    "all_true = []\n",
    "train_data = train[train.expert_numner > NUM_EXPERTS_THRESHOLD]\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "for i, (train_index, valid_index) in enumerate(gkf.split(train_data, train_data.target, train_data.patient_id)):  \n",
    "    \n",
    "    print('#'*25)\n",
    "    print(f'### Fold {i+1}')\n",
    "    \n",
    "    train_gen = DataGenerator(train_data.iloc[train_index], shuffle=True, batch_size=BATCH_SIZE, augment=False)\n",
    "    valid_gen = DataGenerator(train_data.iloc[valid_index], shuffle=False, batch_size=BATCH_SIZE, mode='valid')\n",
    "    \n",
    "    print(f'### train size {len(train_index)}, valid size {len(valid_index)}')\n",
    "    print('#'*25)\n",
    "    \n",
    "    K.clear_session()       \n",
    "    with strategy.scope():\n",
    "        image_size = (512, 512)\n",
    "        num_classes = 6\n",
    "        \n",
    "        model = unet_hidden_crf(image_size = image_size, num_classes=num_classes, num_features=32, trainable=True)\n",
    "        # model = unet_global(image_size = image_size, num_classes=num_classes, num_features=32, trainable=True)\n",
    "        model = build_model(model, None)\n",
    "    if LOAD_MODELS_FROM is None:\n",
    "        model.fit(train_gen, verbose=1,\n",
    "              validation_data = valid_gen,\n",
    "              epochs=EPOCHS, callbacks = [LR2],)\n",
    "        model.save_weights(f'Global_UNet_v{VER}_f{i}.h5')\n",
    "    else:\n",
    "        LOAD_MODELS_FROM = './Models/'\n",
    "        model.load_weights(f'{LOAD_MODELS_FROM}Global_UNet_v{VER}_f{i}.h5')\n",
    "        model.evaluate(valid_gen)\n",
    "        # model.save(f'{LOAD_MODELS_FROM}Global_UNet_v{VER}_f{i}_full.h5')\n",
    "    oof = model.predict(valid_gen, verbose=1)\n",
    "    all_oof.append(oof)\n",
    "    all_true.append(train_data.iloc[valid_index][TARGETS].values)\n",
    "    del model, oof\n",
    "    gc.collect()\n",
    "    \n",
    "all_oof = np.concatenate(all_oof)\n",
    "all_true = np.concatenate(all_true)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
